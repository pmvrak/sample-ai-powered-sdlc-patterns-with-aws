#!/bin/bash

# Real AWS Integration Tests for Document Management API
# Tests against deployed AWS infrastructure - NO MOCKS
# Following steering guidelines: test against real AWS services only

set -e

echo "üöÄ Starting Real AWS Integration Tests"
echo "üìç Region: us-west-2"
echo "üë§ Profile: aidlc_main"

# Configuration from Terraform outputs
API_BASE_URL="https://ojfkk555ge.execute-api.us-west-2.amazonaws.com/dev"
DOCUMENTS_TABLE="ai-assistant-dev-documents"
DOCUMENTS_BUCKET="ai-assistant-dev-documents-e5e9acfe"
KNOWLEDGE_BASE_ID="PQB7MB5ORO"
DATA_SOURCE_ID="YUAUID9BJN"
LAMBDA_FUNCTION="ai-assistant-dev-document-management"

echo "üîó API URL: $API_BASE_URL"
echo "üìä DynamoDB Table: $DOCUMENTS_TABLE"
echo "ü™£ S3 Bucket: $DOCUMENTS_BUCKET"
echo "üß† Knowledge Base: $KNOWLEDGE_BASE_ID"

echo ""
echo "=== Test 1: Verify AWS Resources Exist ==="

echo "üîç Verifying DynamoDB table exists..."
aws dynamodb describe-table --table-name "$DOCUMENTS_TABLE" --profile aidlc_main --region us-west-2 > /dev/null
echo "‚úÖ DynamoDB table exists and accessible"

echo "üîç Verifying S3 bucket exists..."
aws s3api head-bucket --bucket "$DOCUMENTS_BUCKET" --profile aidlc_main --region us-west-2
echo "‚úÖ S3 bucket exists and accessible"

echo "üîç Verifying Lambda function exists..."
aws lambda get-function --function-name "$LAMBDA_FUNCTION" --profile aidlc_main --region us-west-2 > /dev/null
echo "‚úÖ Lambda function exists and accessible"

echo "üîç Verifying Knowledge Base exists..."
aws bedrock-agent get-knowledge-base --knowledge-base-id "$KNOWLEDGE_BASE_ID" --profile aidlc_main --region us-west-2 > /dev/null
echo "‚úÖ Knowledge Base exists and accessible"

echo ""
echo "=== Test 2: Test API Endpoints (Authentication Required) ==="

echo "üîç Testing GET /documents (should return 403 - Missing Authentication Token)..."
RESPONSE=$(curl -s -w "HTTPSTATUS:%{http_code}" -X GET "$API_BASE_URL/documents" -H "Content-Type: application/json")
HTTP_STATUS=$(echo $RESPONSE | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
if [ "$HTTP_STATUS" != "403" ]; then
    echo "‚ùå Expected 403, got $HTTP_STATUS"
    exit 1
fi
echo "‚úÖ GET /documents correctly rejects unauthenticated requests (403)"

echo "üîç Testing DELETE /documents/test (should return 403)..."
RESPONSE=$(curl -s -w "HTTPSTATUS:%{http_code}" -X DELETE "$API_BASE_URL/documents/test" -H "Content-Type: application/json")
HTTP_STATUS=$(echo $RESPONSE | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
if [ "$HTTP_STATUS" != "403" ]; then
    echo "‚ùå Expected 403, got $HTTP_STATUS"
    exit 1
fi
echo "‚úÖ DELETE /documents/{id} correctly rejects unauthenticated requests (403)"

echo "üîç Testing GET /documents/status (should return 403)..."
RESPONSE=$(curl -s -w "HTTPSTATUS:%{http_code}" -X GET "$API_BASE_URL/documents/status" -H "Content-Type: application/json")
HTTP_STATUS=$(echo $RESPONSE | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
if [ "$HTTP_STATUS" != "403" ]; then
    echo "‚ùå Expected 403, got $HTTP_STATUS"
    exit 1
fi
echo "‚úÖ GET /documents/status correctly rejects unauthenticated requests (403)"

echo "üîç Testing CORS preflight..."
RESPONSE=$(curl -s -w "HTTPSTATUS:%{http_code}" -X OPTIONS "$API_BASE_URL/documents" \
    -H "Origin: https://example.com" \
    -H "Access-Control-Request-Method: GET" \
    -H "Access-Control-Request-Headers: Authorization")
HTTP_STATUS=$(echo $RESPONSE | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
if [ "$HTTP_STATUS" != "200" ]; then
    echo "‚ùå CORS preflight failed: $HTTP_STATUS"
    exit 1
fi
echo "‚úÖ CORS preflight working correctly (200)"

echo ""
echo "=== Test 3: Test DynamoDB Integration ==="

TEST_DOC_ID="test-doc-$(date +%s)"
TEST_USER_ID="test-user-$(date +%s)"

echo "üîç Creating test document record in DynamoDB..."
aws dynamodb put-item \
    --table-name "$DOCUMENTS_TABLE" \
    --item '{
        "PK": {"S": "DOC#'$TEST_DOC_ID'"},
        "SK": {"S": "METADATA"},
        "documentId": {"S": "'$TEST_DOC_ID'"},
        "fileName": {"S": "test-document.pdf"},
        "uploadedBy": {"S": "'$TEST_USER_ID'"},
        "uploadDate": {"S": "'$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)'"},
        "s3Key": {"S": "documents/'$TEST_USER_ID'/'$TEST_DOC_ID'.pdf"},
        "s3Bucket": {"S": "'$DOCUMENTS_BUCKET'"},
        "status": {"S": "uploaded"},
        "knowledgeBaseStatus": {"S": "pending"},
        "GSI1PK": {"S": "USER#'$TEST_USER_ID'"},
        "GSI1SK": {"S": "DOC#'$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)'"}
    }' \
    --profile aidlc_main --region us-west-2
echo "‚úÖ Successfully created test document record in DynamoDB"

echo "üîç Querying test document from DynamoDB..."
QUERY_RESULT=$(aws dynamodb query \
    --table-name "$DOCUMENTS_TABLE" \
    --key-condition-expression "PK = :pk AND SK = :sk" \
    --expression-attribute-values '{
        ":pk": {"S": "DOC#'$TEST_DOC_ID'"},
        ":sk": {"S": "METADATA"}
    }' \
    --profile aidlc_main --region us-west-2)

ITEM_COUNT=$(echo "$QUERY_RESULT" | jq '.Items | length')
if [ "$ITEM_COUNT" != "1" ]; then
    echo "‚ùå Failed to retrieve test document from DynamoDB"
    exit 1
fi
echo "‚úÖ Successfully queried document from DynamoDB"

echo "üîç Querying documents by user using GSI..."
GSI_RESULT=$(aws dynamodb query \
    --table-name "$DOCUMENTS_TABLE" \
    --index-name "GSI1" \
    --key-condition-expression "GSI1PK = :userPK" \
    --expression-attribute-values '{
        ":userPK": {"S": "USER#'$TEST_USER_ID'"}
    }' \
    --profile aidlc_main --region us-west-2)

GSI_COUNT=$(echo "$GSI_RESULT" | jq '.Items | length')
if [ "$GSI_COUNT" -lt "1" ]; then
    echo "‚ùå Failed to query documents by user from DynamoDB GSI"
    exit 1
fi
echo "‚úÖ Successfully queried documents by user using GSI"

echo "üîç Cleaning up test document record..."
aws dynamodb delete-item \
    --table-name "$DOCUMENTS_TABLE" \
    --key '{
        "PK": {"S": "DOC#'$TEST_DOC_ID'"},
        "SK": {"S": "METADATA"}
    }' \
    --profile aidlc_main --region us-west-2
echo "‚úÖ Successfully cleaned up test document record"

echo ""
echo "=== Test 4: Test S3 Integration ==="

TEST_S3_KEY="documents/$TEST_USER_ID/test-file-$(date +%s).txt"
TEST_CONTENT="This is a test document for integration testing"

echo "üîç Uploading test file to S3..."
echo "$TEST_CONTENT" | aws s3 cp - "s3://$DOCUMENTS_BUCKET/$TEST_S3_KEY" \
    --content-type "text/plain" \
    --metadata "uploaded-by=$TEST_USER_ID,test-file=true" \
    --profile aidlc_main --region us-west-2
echo "‚úÖ Successfully uploaded test file to S3"

echo "üîç Verifying S3 file exists and has correct metadata..."
S3_METADATA=$(aws s3api head-object \
    --bucket "$DOCUMENTS_BUCKET" \
    --key "$TEST_S3_KEY" \
    --profile aidlc_main --region us-west-2)

UPLOADED_BY=$(echo "$S3_METADATA" | jq -r '.Metadata."uploaded-by"')
if [ "$UPLOADED_BY" != "$TEST_USER_ID" ]; then
    echo "‚ùå S3 metadata not preserved correctly"
    exit 1
fi
echo "‚úÖ Successfully verified S3 file and metadata"

echo "üîç Listing S3 objects with prefix..."
S3_LIST=$(aws s3api list-objects-v2 \
    --bucket "$DOCUMENTS_BUCKET" \
    --prefix "documents/$TEST_USER_ID/" \
    --profile aidlc_main --region us-west-2)

OBJECT_COUNT=$(echo "$S3_LIST" | jq '.Contents | length')
if [ "$OBJECT_COUNT" -lt "1" ]; then
    echo "‚ùå Failed to list S3 objects with prefix"
    exit 1
fi
echo "‚úÖ Successfully listed S3 objects with prefix"

echo "üîç Cleaning up test S3 file..."
aws s3 rm "s3://$DOCUMENTS_BUCKET/$TEST_S3_KEY" --profile aidlc_main --region us-west-2
echo "‚úÖ Successfully cleaned up test S3 file"

echo ""
echo "=== Test 5: Test Knowledge Base Integration ==="

echo "üîç Getting Knowledge Base details..."
KB_DETAILS=$(aws bedrock-agent get-knowledge-base \
    --knowledge-base-id "$KNOWLEDGE_BASE_ID" \
    --profile aidlc_main --region us-west-2)

KB_STATUS=$(echo "$KB_DETAILS" | jq -r '.knowledgeBase.status')
if [ "$KB_STATUS" != "ACTIVE" ]; then
    echo "‚ö†Ô∏è Knowledge Base is not ACTIVE, current status: $KB_STATUS"
else
    echo "‚úÖ Knowledge Base is ACTIVE"
fi

echo "üîç Listing ingestion jobs..."
INGESTION_JOBS=$(aws bedrock-agent list-ingestion-jobs \
    --knowledge-base-id "$KNOWLEDGE_BASE_ID" \
    --data-source-id "$DATA_SOURCE_ID" \
    --max-results 10 \
    --profile aidlc_main --region us-west-2)

JOB_COUNT=$(echo "$INGESTION_JOBS" | jq '.ingestionJobSummaries | length')
echo "‚úÖ Successfully retrieved $JOB_COUNT ingestion jobs"

echo "üîç Getting data source details..."
DATA_SOURCE_DETAILS=$(aws bedrock-agent get-data-source \
    --knowledge-base-id "$KNOWLEDGE_BASE_ID" \
    --data-source-id "$DATA_SOURCE_ID" \
    --profile aidlc_main --region us-west-2)

DS_STATUS=$(echo "$DATA_SOURCE_DETAILS" | jq -r '.dataSource.status')
if [ "$DS_STATUS" != "AVAILABLE" ]; then
    echo "‚ö†Ô∏è Data Source is not AVAILABLE, current status: $DS_STATUS"
else
    echo "‚úÖ Data Source is AVAILABLE"
fi

echo ""
echo "=== Test 6: Test Lambda Function Details ==="

echo "üîç Getting Lambda function configuration..."
LAMBDA_CONFIG=$(aws lambda get-function \
    --function-name "$LAMBDA_FUNCTION" \
    --profile aidlc_main --region us-west-2)

RUNTIME=$(echo "$LAMBDA_CONFIG" | jq -r '.Configuration.Runtime')
MEMORY=$(echo "$LAMBDA_CONFIG" | jq -r '.Configuration.MemorySize')
TIMEOUT=$(echo "$LAMBDA_CONFIG" | jq -r '.Configuration.Timeout')

echo "‚úÖ Lambda function exists: $LAMBDA_FUNCTION"
echo "üìä Runtime: $RUNTIME"
echo "üíæ Memory: ${MEMORY}MB"
echo "‚è±Ô∏è Timeout: ${TIMEOUT}s"

echo "üîç Verifying environment variables..."
ENV_VARS=$(echo "$LAMBDA_CONFIG" | jq -r '.Configuration.Environment.Variables')

REQUIRED_VARS=("DOCUMENTS_BUCKET" "DOCUMENTS_TABLE" "KNOWLEDGE_BASE_ID" "DATA_SOURCE_ID")
for VAR in "${REQUIRED_VARS[@]}"; do
    VALUE=$(echo "$ENV_VARS" | jq -r ".$VAR")
    if [ "$VALUE" == "null" ]; then
        echo "‚ùå Missing required environment variable: $VAR"
        exit 1
    fi
    echo "‚úÖ Environment variable $VAR: $VALUE"
done

echo ""
echo "=== Test 7: Test API Gateway Integration ==="

echo "üîç Testing API Gateway deployment..."
API_INFO=$(aws apigateway get-rest-api --rest-api-id "ojfkk555ge" --profile aidlc_main --region us-west-2)
API_NAME=$(echo "$API_INFO" | jq -r '.name')
echo "‚úÖ API Gateway exists: $API_NAME"

echo "üîç Testing API Gateway resources..."
RESOURCES=$(aws apigateway get-resources --rest-api-id "ojfkk555ge" --profile aidlc_main --region us-west-2)
RESOURCE_COUNT=$(echo "$RESOURCES" | jq '.items | length')
echo "‚úÖ API Gateway has $RESOURCE_COUNT resources configured"

# Check for specific resources
DOCUMENTS_RESOURCE=$(echo "$RESOURCES" | jq '.items[] | select(.pathPart == "documents")')
if [ -z "$DOCUMENTS_RESOURCE" ]; then
    echo "‚ùå /documents resource not found"
    exit 1
fi
echo "‚úÖ /documents resource exists"

STATUS_RESOURCE=$(echo "$RESOURCES" | jq '.items[] | select(.pathPart == "status")')
if [ -z "$STATUS_RESOURCE" ]; then
    echo "‚ùå /documents/status resource not found"
    exit 1
fi
echo "‚úÖ /documents/status resource exists"

ID_RESOURCE=$(echo "$RESOURCES" | jq '.items[] | select(.pathPart == "{id}")')
if [ -z "$ID_RESOURCE" ]; then
    echo "‚ùå /documents/{id} resource not found"
    exit 1
fi
echo "‚úÖ /documents/{id} resource exists"

echo ""
echo "‚úÖ ALL REAL AWS INTEGRATION TESTS PASSED!"
echo ""
echo "üéâ Summary:"
echo "   ‚úÖ All AWS resources exist and are accessible"
echo "   ‚úÖ API endpoints are deployed and responding correctly"
echo "   ‚úÖ Authentication is working (rejecting unauthenticated requests)"
echo "   ‚úÖ CORS is configured properly"
echo "   ‚úÖ DynamoDB integration is working (CRUD operations)"
echo "   ‚úÖ S3 integration is working (upload, metadata, cleanup)"
echo "   ‚úÖ Knowledge Base integration is working"
echo "   ‚úÖ Lambda function is deployed with correct configuration"
echo "   ‚úÖ API Gateway is properly configured with all resources"
echo ""
echo "üöÄ Document Management API is fully deployed and functional on AWS!"